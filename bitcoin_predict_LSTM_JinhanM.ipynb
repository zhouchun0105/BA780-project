{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bitcoin predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPo2k6sJWVOUXGhQSfhdkom",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhouchun0105/Bitcoin-Price-and-Movement-Prediction/blob/main/bitcoin_predict_LSTM_JinhanM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsoOFOKBBOX",
        "outputId": "34ec7595-d95e-481d-ee93-903434e208d8"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "HhA7rqHVNKnw",
        "outputId": "65e1f03c-b85d-47b2-b21c-861fbb2b3709"
      },
      "source": [
        "df = pd.read_csv('drive/MyDrive/bitcoin.csv')\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'],unit='s')\n",
        "df = df.set_index('Timestamp')\n",
        "df.columns = [\"Open\", \"High\", \"Low\",\"Close\", \"Volume_BTC\", \"Volume_Currency\", \"Weighted_Price\"]\n",
        "df.dropna(inplace=True)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume_BTC</th>\n",
              "      <th>Volume_Currency</th>\n",
              "      <th>Weighted_Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-12-31 07:52:00</th>\n",
              "      <td>4.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>0.455581</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-12-31 15:50:00</th>\n",
              "      <td>4.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>210.720000</td>\n",
              "      <td>4.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-12-31 16:59:00</th>\n",
              "      <td>4.50</td>\n",
              "      <td>4.57</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.57</td>\n",
              "      <td>37.862297</td>\n",
              "      <td>171.380338</td>\n",
              "      <td>4.526411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-12-31 17:00:00</th>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>41.220000</td>\n",
              "      <td>4.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-01 04:16:00</th>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>1.502000</td>\n",
              "      <td>6.879160</td>\n",
              "      <td>4.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-01 15:28:00</th>\n",
              "      <td>4.84</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.84</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>48.400000</td>\n",
              "      <td>4.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-01 22:45:00</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>10.100000</td>\n",
              "      <td>50.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-02 20:04:00</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>19.048000</td>\n",
              "      <td>95.240000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-03 11:45:00</th>\n",
              "      <td>5.32</td>\n",
              "      <td>5.32</td>\n",
              "      <td>5.32</td>\n",
              "      <td>5.32</td>\n",
              "      <td>2.419173</td>\n",
              "      <td>12.870000</td>\n",
              "      <td>5.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-03 14:22:00</th>\n",
              "      <td>5.14</td>\n",
              "      <td>5.14</td>\n",
              "      <td>5.14</td>\n",
              "      <td>5.14</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>3.495200</td>\n",
              "      <td>5.140000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Open  High  ...  Volume_Currency  Weighted_Price\n",
              "Timestamp                        ...                                 \n",
              "2011-12-31 07:52:00  4.39  4.39  ...         2.000000        4.390000\n",
              "2011-12-31 15:50:00  4.39  4.39  ...       210.720000        4.390000\n",
              "2011-12-31 16:59:00  4.50  4.57  ...       171.380338        4.526411\n",
              "2011-12-31 17:00:00  4.58  4.58  ...        41.220000        4.580000\n",
              "2012-01-01 04:16:00  4.58  4.58  ...         6.879160        4.580000\n",
              "2012-01-01 15:28:00  4.84  4.84  ...        48.400000        4.840000\n",
              "2012-01-01 22:45:00  5.00  5.00  ...        50.500000        5.000000\n",
              "2012-01-02 20:04:00  5.00  5.00  ...        95.240000        5.000000\n",
              "2012-01-03 11:45:00  5.32  5.32  ...        12.870000        5.320000\n",
              "2012-01-03 14:22:00  5.14  5.14  ...         3.495200        5.140000\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DJvaSVCN1sx"
      },
      "source": [
        "df[\"Price\"] = df[[\"Open\",\"High\",\"Low\",\"Close\"]].mean(axis=1)\n",
        "df[\"Return\"] = df[\"Price\"].diff()\n",
        "df[\"Percentage_Return\"] = ((df[\"Return\"].shift(periods=-1))/ (df[\"Price\"])).shift(periods=1)\n",
        "df[\"Volume_diff\"] = df[\"Volume_Currency\"].diff()\n",
        "df[\"Percentage_Volume\"] = ((df[\"Volume_diff\"].shift(periods=-1))/ (df[\"Price\"])).shift(periods=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "yRavuX0TN7Pf",
        "outputId": "7e9e3222-2075-40d5-e518-9490d00f98ef"
      },
      "source": [
        "low, high = 0.01, 0.99\n",
        "selected_columns = [\"Percentage_Return\", \"Percentage_Volume\"]\n",
        "\n",
        "quant_df = df[selected_columns].quantile([low, high])\n",
        "quant_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Percentage_Return</th>\n",
              "      <th>Percentage_Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.01</th>\n",
              "      <td>-0.004313</td>\n",
              "      <td>-83.656998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.99</th>\n",
              "      <td>0.004219</td>\n",
              "      <td>85.030174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Percentage_Return  Percentage_Volume\n",
              "0.01          -0.004313         -83.656998\n",
              "0.99           0.004219          85.030174"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV7fgrmjOBLu"
      },
      "source": [
        "for col in selected_columns:\n",
        "    df.drop(df[df[col] <= quant_df.loc[low, col]].index, axis=0, inplace=True)\n",
        "    df.drop(df[df[col] >= quant_df.loc[high, col]].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9xm2qr7OFr0"
      },
      "source": [
        "stamp1 = pd.Timestamp(2014,6,1)\n",
        "df = df[df.index>stamp1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "dkhIyVS1OQ2J",
        "outputId": "a5ebc7bf-ef25-4a05-aa37-ff9c3e75ba54"
      },
      "source": [
        "df_t = df[[\"Volume_Currency\", \"Weighted_Price\"]].copy(deep=True)\n",
        "times = [2, 120, 240, 600, 1440, 14400, 28800]\n",
        "for col in df_t.columns:\n",
        "    for t in times:\n",
        "        df_t[col+'_ratio_'+str(t)] = df_t[col]/df_t[col].rolling(window=t).mean()\n",
        "df_t.dropna(inplace=True)\n",
        "columns = df_t.columns.tolist()\n",
        "columns = [columns[11]] + columns[:11] + columns[12:]\n",
        "df_t = df_t[columns]\n",
        "df_t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted_Price_ratio_240</th>\n",
              "      <th>Volume_Currency</th>\n",
              "      <th>Weighted_Price</th>\n",
              "      <th>Volume_Currency_ratio_2</th>\n",
              "      <th>Volume_Currency_ratio_120</th>\n",
              "      <th>Volume_Currency_ratio_240</th>\n",
              "      <th>Volume_Currency_ratio_600</th>\n",
              "      <th>Volume_Currency_ratio_1440</th>\n",
              "      <th>Volume_Currency_ratio_14400</th>\n",
              "      <th>Volume_Currency_ratio_28800</th>\n",
              "      <th>Weighted_Price_ratio_2</th>\n",
              "      <th>Weighted_Price_ratio_120</th>\n",
              "      <th>Weighted_Price_ratio_600</th>\n",
              "      <th>Weighted_Price_ratio_1440</th>\n",
              "      <th>Weighted_Price_ratio_14400</th>\n",
              "      <th>Weighted_Price_ratio_28800</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-07-01 13:20:00</th>\n",
              "      <td>1.008167</td>\n",
              "      <td>149.643129</td>\n",
              "      <td>652.755990</td>\n",
              "      <td>0.494116</td>\n",
              "      <td>0.040897</td>\n",
              "      <td>0.049898</td>\n",
              "      <td>0.040948</td>\n",
              "      <td>0.035313</td>\n",
              "      <td>0.050734</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>1.000955</td>\n",
              "      <td>1.005684</td>\n",
              "      <td>1.010230</td>\n",
              "      <td>1.025384</td>\n",
              "      <td>1.097148</td>\n",
              "      <td>1.061968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-07-01 13:21:00</th>\n",
              "      <td>1.008528</td>\n",
              "      <td>2037.418383</td>\n",
              "      <td>653.018712</td>\n",
              "      <td>1.863156</td>\n",
              "      <td>0.555999</td>\n",
              "      <td>0.677806</td>\n",
              "      <td>0.557247</td>\n",
              "      <td>0.480772</td>\n",
              "      <td>0.690723</td>\n",
              "      <td>0.526918</td>\n",
              "      <td>1.000201</td>\n",
              "      <td>1.005959</td>\n",
              "      <td>1.010613</td>\n",
              "      <td>1.025769</td>\n",
              "      <td>1.097577</td>\n",
              "      <td>1.062393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-07-01 13:23:00</th>\n",
              "      <td>1.009636</td>\n",
              "      <td>1677.587661</td>\n",
              "      <td>653.764882</td>\n",
              "      <td>0.903141</td>\n",
              "      <td>0.456137</td>\n",
              "      <td>0.556909</td>\n",
              "      <td>0.458482</td>\n",
              "      <td>0.396185</td>\n",
              "      <td>0.568723</td>\n",
              "      <td>0.433983</td>\n",
              "      <td>1.000571</td>\n",
              "      <td>1.006984</td>\n",
              "      <td>1.011743</td>\n",
              "      <td>1.026914</td>\n",
              "      <td>1.098819</td>\n",
              "      <td>1.063606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-07-01 13:24:00</th>\n",
              "      <td>1.006434</td>\n",
              "      <td>13034.225000</td>\n",
              "      <td>651.711250</td>\n",
              "      <td>1.771940</td>\n",
              "      <td>3.473215</td>\n",
              "      <td>4.262214</td>\n",
              "      <td>3.546248</td>\n",
              "      <td>3.071833</td>\n",
              "      <td>4.417423</td>\n",
              "      <td>3.371495</td>\n",
              "      <td>0.998427</td>\n",
              "      <td>1.003695</td>\n",
              "      <td>1.008546</td>\n",
              "      <td>1.023664</td>\n",
              "      <td>1.095355</td>\n",
              "      <td>1.060263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-07-01 13:25:00</th>\n",
              "      <td>1.006079</td>\n",
              "      <td>117.270000</td>\n",
              "      <td>651.500000</td>\n",
              "      <td>0.017834</td>\n",
              "      <td>0.032981</td>\n",
              "      <td>0.038602</td>\n",
              "      <td>0.031936</td>\n",
              "      <td>0.027641</td>\n",
              "      <td>0.039744</td>\n",
              "      <td>0.030334</td>\n",
              "      <td>0.999838</td>\n",
              "      <td>1.003231</td>\n",
              "      <td>1.008200</td>\n",
              "      <td>1.023307</td>\n",
              "      <td>1.094988</td>\n",
              "      <td>1.059918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-30 23:56:00</th>\n",
              "      <td>0.999584</td>\n",
              "      <td>81259.372187</td>\n",
              "      <td>58692.753339</td>\n",
              "      <td>0.708872</td>\n",
              "      <td>1.198122</td>\n",
              "      <td>1.001461</td>\n",
              "      <td>0.738670</td>\n",
              "      <td>0.588387</td>\n",
              "      <td>0.463320</td>\n",
              "      <td>0.421717</td>\n",
              "      <td>0.999666</td>\n",
              "      <td>0.999355</td>\n",
              "      <td>0.998660</td>\n",
              "      <td>1.006009</td>\n",
              "      <td>1.056144</td>\n",
              "      <td>1.036530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-30 23:57:00</th>\n",
              "      <td>0.999611</td>\n",
              "      <td>428158.146640</td>\n",
              "      <td>58693.226508</td>\n",
              "      <td>1.680971</td>\n",
              "      <td>6.051692</td>\n",
              "      <td>5.232474</td>\n",
              "      <td>3.871621</td>\n",
              "      <td>3.096415</td>\n",
              "      <td>2.440925</td>\n",
              "      <td>2.221882</td>\n",
              "      <td>1.000004</td>\n",
              "      <td>0.999378</td>\n",
              "      <td>0.998673</td>\n",
              "      <td>1.006005</td>\n",
              "      <td>1.056152</td>\n",
              "      <td>1.036537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-30 23:58:00</th>\n",
              "      <td>0.999682</td>\n",
              "      <td>100117.070370</td>\n",
              "      <td>58696.198496</td>\n",
              "      <td>0.379034</td>\n",
              "      <td>1.398912</td>\n",
              "      <td>1.226897</td>\n",
              "      <td>0.908864</td>\n",
              "      <td>0.723793</td>\n",
              "      <td>0.570747</td>\n",
              "      <td>0.519555</td>\n",
              "      <td>1.000025</td>\n",
              "      <td>0.999441</td>\n",
              "      <td>0.998728</td>\n",
              "      <td>1.006043</td>\n",
              "      <td>1.056206</td>\n",
              "      <td>1.036588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-30 23:59:00</th>\n",
              "      <td>1.000817</td>\n",
              "      <td>42332.958633</td>\n",
              "      <td>58761.866202</td>\n",
              "      <td>0.594355</td>\n",
              "      <td>0.588815</td>\n",
              "      <td>0.520669</td>\n",
              "      <td>0.384682</td>\n",
              "      <td>0.306684</td>\n",
              "      <td>0.241329</td>\n",
              "      <td>0.219694</td>\n",
              "      <td>1.000559</td>\n",
              "      <td>1.000557</td>\n",
              "      <td>0.999848</td>\n",
              "      <td>1.007155</td>\n",
              "      <td>1.057387</td>\n",
              "      <td>1.037746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-31 00:00:00</th>\n",
              "      <td>1.000878</td>\n",
              "      <td>159417.751000</td>\n",
              "      <td>58764.349363</td>\n",
              "      <td>1.580344</td>\n",
              "      <td>2.177480</td>\n",
              "      <td>1.953007</td>\n",
              "      <td>1.446219</td>\n",
              "      <td>1.154274</td>\n",
              "      <td>0.908756</td>\n",
              "      <td>0.827405</td>\n",
              "      <td>1.000021</td>\n",
              "      <td>1.000599</td>\n",
              "      <td>0.999895</td>\n",
              "      <td>1.007184</td>\n",
              "      <td>1.057431</td>\n",
              "      <td>1.037789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000136 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Weighted_Price_ratio_240  ...  Weighted_Price_ratio_28800\n",
              "Timestamp                                      ...                            \n",
              "2014-07-01 13:20:00                  1.008167  ...                    1.061968\n",
              "2014-07-01 13:21:00                  1.008528  ...                    1.062393\n",
              "2014-07-01 13:23:00                  1.009636  ...                    1.063606\n",
              "2014-07-01 13:24:00                  1.006434  ...                    1.060263\n",
              "2014-07-01 13:25:00                  1.006079  ...                    1.059918\n",
              "...                                       ...  ...                         ...\n",
              "2021-03-30 23:56:00                  0.999584  ...                    1.036530\n",
              "2021-03-30 23:57:00                  0.999611  ...                    1.036537\n",
              "2021-03-30 23:58:00                  0.999682  ...                    1.036588\n",
              "2021-03-30 23:59:00                  1.000817  ...                    1.037746\n",
              "2021-03-31 00:00:00                  1.000878  ...                    1.037789\n",
              "\n",
              "[3000136 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfwgbkJyQF0a",
        "outputId": "7e7d072d-87ab-450e-ce11-e973f19aa363"
      },
      "source": [
        "time_stamp_2021 = pd.Timestamp(2021, 1, 1)\n",
        "train_df = df[df.index < time_stamp_2021]\n",
        "test_df = df[df.index > time_stamp_2021]\n",
        "len(train_df)/len(df_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9674151438468123"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZELbNEIL39nD",
        "outputId": "c85f74f6-441c-4b95-fe71-19edcf1a6194"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "train_df = scaler.fit_transform(train_df)\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2902377, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etce955YBOxg",
        "outputId": "d9e41a49-0721-4191-8f96-e59dbf7aaf16"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01583404, 0.01582218, 0.01588679, ..., 0.59519076, 0.50732711,\n",
              "        0.49660061],\n",
              "       [0.01583404, 0.01582218, 0.01579058, ..., 0.24414874, 0.51450412,\n",
              "        0.81381142],\n",
              "       [0.01573106, 0.01571921, 0.01578371, ..., 0.20614355, 0.50010984,\n",
              "        0.1768978 ],\n",
              "       ...,\n",
              "       [0.99106147, 0.99137168, 0.9916245 , ..., 0.47117533, 0.58049669,\n",
              "        0.56584927],\n",
              "       [0.99124202, 0.99137134, 0.99082935, ..., 0.44238831, 0.54358537,\n",
              "        0.53059991],\n",
              "       [0.98910187, 0.99054651, 0.98978851, ..., 0.38032734, 0.41758953,\n",
              "        0.41016096]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S58r2z7jArsI"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps=30):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "train_X, train_y = split_sequences(train_df)\n",
        "n_features = train_X.shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bq7a1bw09v9"
      },
      "source": [
        "pip install -q pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzSczEqbhwAr"
      },
      "source": [
        "checkpoint_path = 'drive/MyDrive/checkpoint/'\n",
        "import tensorflow as tf\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE3xWRaqbli0",
        "outputId": "fe99b986-116a-4d6c-c147-99a645fc5aae"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct  6 18:27:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1XFLGcaCpLN"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='tanh', return_sequences=True, input_shape=(30, n_features)))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(LSTM(100, return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "# model.add(Dense(output_dim=1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "JWfrrOThY06m",
        "outputId": "876c5e31-9af2-4dcb-873a-0f7e11bdc5d8"
      },
      "source": [
        "history = model.fit(train_X, train_y, batch_size=32, epochs=100, verbose=2, validation_split=0.25, callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d251b8f4171d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer sequential_4: expected shape=(None, None, 2), found shape=(None, 30, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n758aOwg1iwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3978d9-c433-4fda-f808-d8d7be20c266"
      },
      "source": [
        "# from numpy import array\n",
        "# from numpy import hstack\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import LSTM\n",
        "# from keras.layers import Dense\n",
        " \n",
        "# # split a multivariate sequence into samples\n",
        "# def split_sequences(sequences, n_steps):\n",
        "# \tX, y = list(), list()\n",
        "# \tfor i in range(len(sequences)):\n",
        "# \t\t# find the end of this pattern\n",
        "# \t\tend_ix = i + n_steps\n",
        "# \t\t# check if we are beyond the dataset\n",
        "# \t\tif end_ix > len(sequences):\n",
        "# \t\t\tbreak\n",
        "# \t\t# gather input and output parts of the pattern\n",
        "# \t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "# \t\tX.append(seq_x)\n",
        "# \t\ty.append(seq_y)\n",
        "# \treturn array(X), array(y)\n",
        " \n",
        "# # define input sequence\n",
        "# in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "# in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "# out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# # convert to [rows, columns] structure\n",
        "# in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "# in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "# out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# # horizontally stack columns\n",
        "# dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# # choose a number of time steps\n",
        "# n_steps = 3\n",
        "# # convert into input/output\n",
        "# X, y = split_sequences(dataset, n_steps)\n",
        "# # the dataset knows the number of features, e.g. 2\n",
        "# n_features = X.shape[2]\n",
        "# # define model\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "# model.add(Dense(1))\n",
        "# model.compile(optimizer='adam', loss='mse')\n",
        "# # fit model\n",
        "# model.fit(X, y, epochs=200, verbose=2)\n",
        "# # demonstrate prediction\n",
        "# x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "# x_input = x_input.reshape((1, n_steps, n_features))\n",
        "# yhat = model.predict(x_input, verbose=0)\n",
        "# print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 16006.6982\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 15802.9131\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 15632.6973\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 15488.3213\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 15363.1689\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 15251.9863\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 15150.6953\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 15056.1387\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 14965.8574\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 14877.8076\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 14790.2715\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 14701.7676\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 14610.9639\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 14516.7363\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 14418.1113\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 14314.4189\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 14205.4395\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 14091.4268\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 13973.1123\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 13851.8857\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 13729.1768\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 13606.3574\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 13484.5859\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 13364.2031\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 13245.2725\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 13127.2393\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 13009.2646\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 12890.2285\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 12768.7764\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 12644.1357\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 12514.8750\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 12379.4062\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 12236.5420\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 12084.1455\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 11919.9014\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 11740.9297\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 11543.9951\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 11325.0146\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 11081.4111\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 10808.5859\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 10508.8389\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 10191.7236\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 9867.5186\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 9539.4893\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 9200.6270\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 8834.0732\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 8413.2158\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 7904.4150\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 7289.9478\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 6590.3838\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 5847.6787\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 5080.0415\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 4280.8042\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 3443.8237\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 2597.0310\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1836.2625\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1247.0381\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 822.3453\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 527.2918\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 332.1124\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 217.4826\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 171.9859\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 186.2853\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 244.6141\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 323.0913\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 399.8347\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 459.4590\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 493.5962\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 500.3096\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 481.9731\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 443.7045\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 391.7664\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 332.5206\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 272.4664\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 217.7577\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 171.8249\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 136.6423\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 111.8985\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 96.5577\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 89.3721\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 89.0245\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 93.9677\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 99.9271\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 102.6976\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 102.2384\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 99.8113\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 95.8537\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 90.3621\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 83.4971\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 75.7093\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 67.6952\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 60.7819\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 56.6538\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 54.9763\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 52.0479\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 46.4899\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 40.1096\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 33.4479\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 27.2086\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 22.1113\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 18.2970\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 15.5731\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 13.4693\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 11.6148\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 9.9915\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 8.7312\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 7.7106\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 6.6805\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 5.7628\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 5.1188\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 4.6438\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 4.2107\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 3.8434\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 3.6004\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 3.4116\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 3.1736\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 2.9156\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 2.6887\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 2.4580\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 2.1998\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 1.9717\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 1.8164\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 1.6719\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 1.5205\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 1.4282\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 1.3650\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 1.2695\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 1.1711\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 1.0893\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.9824\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.8753\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.8011\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.7334\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.6723\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.6402\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.6149\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.5813\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.5564\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.5311\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.4940\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.4617\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.4357\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.4052\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3835\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3703\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.3552\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.3464\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.3398\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.3284\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.3204\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.3106\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2981\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2894\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2790\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2700\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2642\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2569\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2518\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2466\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2400\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2347\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2276\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2209\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2147\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2079\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2026\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.1970\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.1921\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.1876\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.1825\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1781\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1730\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1683\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1636\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1589\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1547\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1504\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1467\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1428\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1392\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1356\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1319\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1284\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1248\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1214\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1180\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1148\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1117\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1087\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1057\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1028\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.0999\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.0971\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.0943\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.0916\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.0890\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.0864\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.0840\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.0815\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.0792\n",
            "[[206.13666]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGy9Fz1jgMcP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}